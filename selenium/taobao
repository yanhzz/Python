# -*- coding:utf-8 -*-
# selenium爬取淘宝信息

import re
from selenium import webdriver
from selenium.common.exceptions import TimeoutException
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from pyquery import PyQuery as pq
from config import *
import pymongo

client = pymongo.MongoClient(MONGO_URL) #MogoDB配置
db = client[MONGO_DB]

browser = webdriver.Chrome()    #创建WebDriver对象
wait = WebDriverWait(browser,10)   #等待变量

def search():
    try:
        browser.get('https://www.taobao.com/')
         #等待输入框加载完成
        input = wait.until(   
            EC.presence_of_element_located((By.CSS_SELECTOR,'#q'))#Chrome-检查-选中-html代码处右键-Copy-Copy Selector即可
        )
        #等待搜索按钮加载完成
        submit = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR,'#J_TSearchForm > div.search-button > button')))
        input.send_keys('美食')
        submit.click()
        #加载完成，获取页数元素
        total=wait.until(EC.presence_of_element_located((By.CSS_SELECTOR,'#mainsrp-pager > div > div > div > div.total')))
        return total.text  #获取元素中的文本
    except TimeoutException:  #若发生异常，重新调用自己
        return search()

#翻页函数
def next_page(page_number):
    try:
    #等待翻页输入框加载完成
        input = wait.until(
            EC.presence_of_element_located((By.CSS_SELECTOR,'#mainsrp-pager > div > div > div > div.form > input'))
        )
        #等待确认按钮加载完成
        submit = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR,'#mainsrp-pager > div > div > div > div.form > span.btn.J_Submit')))
        input.clear()#清空翻页输入框
        input.send_keys(page_number)#传入页数
        submit.click()#确认点击翻页
        #确认已翻到page_number页
        wait.until(EC.text_to_be_present_in_element((By.CSS_SELECTOR,'#mainsrp-itemlist'),str(page_number)))
        get_product()
    except TimeoutException:#若发生异常，重新调用
        next_page(page_number)
        get_product()

#获取商品信息
def get_product():
    #等待商品信息加载完成
    wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, '#mainsrp-itemlist .items .item')))
    html = browser.page_source #得到页面HTML源码
    doc = pq(html)#创建PyQuery对象
    items = doc('#mainsrp-itemlist .items .item').items()#获取当前页所有商品信息的html源码
    for item in items:
        product = {
            'image':item.find('.pic .img').attr('src'),
            'price':item.find('.price').text(),
            'deal':item.find('.deal-cnt').text()[:-3],
            'title':item.find('.title').text(),
            'shop':item.find('.shop').text(),
            'location':item.find('.location').text()
        }
        print(product)
        save_to_mongo(product)
        
#保存到MongoDB
def save_to_mongo(result):
    try:
        if db[MONGO_TABLE].insert(result):
            print('存储到Mongodb成功',result)
    except Exception:
        print('存储到Mongodb失败',result)


def main():
    total = search()#获取商品页数，字符串类型
    total=int(re.compile('(\d+)').search(total).group(1))#利用正则表达式提取数字，并强制转换为int类型
    for i in range(2,total+1):
        next_page(i)
    browser.close()

if __name__ == '__main__':
    main()
